import os
from subprocess import check_call as run
from datetime import datetime as dt
import pandas as pd

ansii_colors = {
    "magenta": "[1;35;2m",
    "green": "[1;9;2m",
    "red": "[1;31;1m",
    "cyan": "[1;36;1m",
    "gray": "[1;30;1m",
    "black": "[0m",
}

colors = {
    "process": ansii_colors["green"],
    "time": ansii_colors["magenta"],
    "normal": ansii_colors["gray"],
    "warning": ansii_colors["red"],
    "success": ansii_colors["cyan"],
}


def show_output(text, color="normal", multi=False, time=True, **kwargs):
    """
    get colored output to the terminal
    """
    time = (
        f"\033{colors['time']}{dt.now().strftime('%H:%M:%S')}\033[0m : " if time else ""
    )
    proc = f"\033{colors['process']}Process {os.getpid()}\033[0m : " if multi else ""
    text = f"\033{colors[color]}{text}\033[0m"
    print(time + proc + text, **kwargs)


def show_command(command, list=False, multi=True, **kwargs):
    """
    prints the command line if debugging is active
    """

    if list:
        command = f"\033[1m$ {' '.join(command)}\033[0m"
    else:
        command = f"\033[1m$ {command}\033[0m"
    print(proc + command, **kwargs)
    return


def run_cmd(cmd, multi=False):
    show_command(cmd, multi=multi)
    exit = run(cmd, shell=True)


def sort_df(df, cols={"Chr": True, "Start": True}):
    """
    helper for sorting dfs for chromosomes using Chr, Start + cols in cols
    """
    # make Chr column categorical for sorting .. and sort
    chrom_list = [f"chr{i}" for i in range(23)] + ["chrX", "chrY"]

    df["Chr"] = pd.Categorical(df["Chr"], chrom_list)
    return df.sort_values(list(cols.keys()), ascending=list(cols.values()))




# ############ FILTER_BAM UTILS ########################################################
def reduce_regions(df, padding):
    '''
    takes a mutation list and returns a region list using padding
    overlapping regions are reduced to one using the gap strategy
    '''

    df = df.sort_values('Start')
    df['Start'] = df['Start'] - padding
    df['End'] = df['End'] + padding
    # find the break points
    # if Start is greater than previous End (using shift), this is a gap --> df['gap'] = 1
    df['gap'] = df['Start'].gt(df['End'].shift()).astype('int')
    # id different reads according to gap
    # cumulative sum does not increase at df['gap'] == 0 and so these consecutive stretches are grouped together
    df['gap'] = df['gap'].cumsum()
    # groupby the coverage break group and condense individual coverage islands
    # agg has to contain the neccessary shared columns TransLength because it is needed for coverage computation
    df = df.groupby('gap').agg({'Chr': 'first', 'Start': 'min', 'End': 'max'})
    return df.reset_index('gap').drop(columns='gap')


def mut2bed(mut_df, padding, output):
    # get the bedfile with padded and collapsed regions
    bed_df = reduce_regions(mut_df.sort_values(
        ['Chr', 'Start']).iloc[:, :5], padding)

    # write bed_df to file
    bed_df.to_csv(output, index=False, sep='\t', header=False)
    return output


def get_mut_bed(_, input, output):
    '''
    serves as a params function creating and returning the bed file for the samtools view
    '''

    folder = os.path.dirname(output[0])

    if not os.path.exists(folder):
        print(f"Creating folder {folder}")
        os.makedirs(folder)

    conf = config['filter_bam']
    padding = conf['padding']
    mut_df = pd.read_csv(input.filter_file, sep='\t')
    # empty file
    ext = os.path.splitext(output[0])[1]
    output_file = output[0].replace(ext, ".bed")
    if not len(mut_df.index):
        mut_df.to_csv(output_file, index=False, sep='\t', header=False)
        return output_file
    bed_file = mut2bed(mut_df, padding, output_file)
    return bed_file


def add_config(config, path="", config_name=""):
    '''
    update the config file with a config either 
    - from a path relative to snakedir
    - from a config name listed in the configs list
    '''
    if config_name:
        config_file = os.path.join(snakedir, config['configs'][config_name])
    else:
        config_file = os.path.join(snakedir, path)

    with open(config_file, "r") as stream:
        added_config = load(stream, Loader=Loader)
        config.update(added_config)
    return config