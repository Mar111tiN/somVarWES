import pandas as pd
import os
import re


############# SNAKEFILE ###########################
def get_files(folder_list, sample_sheet):
    '''
    retrieves the path to all the files in the sample_sheet
    if rerun == False, it looks for fastq files
    if rerun == True, it looks for bam files
    '''

    # check whether single folder or folder list
    if len(folder_list[0]) == 1:
        folder_list = [folder_list]
    # check full path or append path to scriptdir
    if not sample_sheet.startswith('/'):
        sample_sheet = os.path.join(snakedir, sample_sheet)
    # import the sample sheet
    samples = pd.read_csv(sample_sheet, sep='\t', index_col=0).set_index('name')


    bam_list = []
    short_list = []
    # cycle through the input folders and look for matching bam files
    for input_folder in folder_list:
        print(f"Looking for bam files in {input_folder}")
        for folder, _, files in os.walk(input_folder):
            for file in files:
                if '.bam' in file and '.md5' not in file and '.bai' not in file:
                    bam_list.append(os.path.join(folder, file))
                    short_list.append(file)

    # include check for empty list
    def get_bam_paths(row, bam_list=None):
        '''
        go through the sample list and find the respective read and index bams in the respective bam_list
        '''

        for file in bam_list:
            # get the basename
            base_file = os.path.basename(file)
            if row['sample'] in base_file and not "chr" in base_file:
                row['bam_path'] = file
        return row

    samples_df = samples.apply(get_bam_paths, axis=1, bam_list=bam_list)
    short_df = samples.apply(get_bam_paths, axis=1, bam_list=short_list)

    # # remove leading zeros
    # samples_df.index = samples_df.index.str.lstrip('0')
    # short_df.index = short_df.index.str.lstrip('0')
    # ########## DEBUG #################
    print(short_df)
    # print(samples_df)
    # ##################################

    return samples_df, short_df


def get_tumor_normal_pairs(samples):
    '''
    turns valid_file_info into tuples of valid tumor normal pairs
    '''

    samples = samples.reset_index()
    # extract the tumor-normal suffix (Name_A --> sample: "Name", TN: "A")
    samples[['sample', 'TN']] = samples['name'].str.extract('(?P<sample>^[^_]+)_(?P<TN>[^_]+)$')
    
    tumor = config['samples']['tumor']
    normal = config['samples']['normal']
    
    def TN_pair(group, l=[]):

        for n in normal:
            if n in list(group['TN']):
                for t in tumor:
                    if t in list(group['TN']):
                        TN_list.append(f"{group['sample'].iloc[0]}_{t}-{n}")
    TN_list = []
    # append in an apply 
    samples.groupby('sample').apply(TN_pair, l=TN_list).reset_index()
    ########## DEBUG #################
    # print(TN_list)
    ##################################
    return TN_list


def get_bam_path(w):
    '''
    returns the bam path from the wildcards object depending on the context
    '''

    ## get the wildcard atributes into wcs
    wcs = vars(w)['_names'].keys()
    if 'type' in wcs:
        sample_name = f"{w.sample}_{w.type}"
    # for filterbam wildcards contain tumor and type but type is needed
    # elif takes care of that
    elif 'tumor' in wcs:
        sample_name = f"{w.sample}_{w.tumor}"
    return sample_df.loc[sample_name]['bam_path']

########### GENERAL ##########################


def get_shell(script_name):
    '''
    takes the script_name and returns abspath to shell script located in snakedir/scripts/shell
    '''
    return os.path.join(scriptdir, f"shell/{script_name}")


def full_path(file):

    '''
    returns the full path to a reference
    '''

    build = config['ref']['build']
    full_ref_path = os.path.join(config['paths']['static'], config['ref'][build][file])
    return full_ref_path


def get_ref(w):
    '''
    returns the path to the ref genome
    if wildcards contains chrom, the genome split version is returned
    '''

    ## get the wildcard atributes into wcs
    wcs = vars(w)['_names'].keys()
    # get genome split
    if "chrom" in wcs:
        return os.path.join(full_path("genome_split"), f"{w.chrom}.fa")
    else:
        return full_path("genome")

def static_path(file):
    '''
    returns the absolute path when given relative to static folder
    '''

    return os.path.join(config['paths']['static'], file)


########### VARSCAN ###########################
def get_bam_pair(w):
    '''
    returns the tumor_bam-normal_bam pair from the wildcards object depending on the context
    '''
    tumor = f"{w.sample}_{w.tumor}"
    normal = f"{w.sample}_{w.normal}"
    return dict(
        tumor_bam=sample_df.loc[tumor]['bam_path'],
        normal_bam=sample_df.loc[normal]['bam_path']
    )


def get_anno_input(_):
    if config['varscan']['vcf']:
        indel = "varscan/{sample}_{tumor}-{normal}.{chrom}.indel.vcf"
        snp = "varscan/{sample}_{tumor}-{normal}.{chrom}.snp.vcf"
    else:
        indel = "varscan/{sample}_{tumor}-{normal}.{chrom}.indel"
        snp = "varscan/{sample}_{tumor}-{normal}.{chrom}.snp"
    return {'indel': indel, 'snp': snp}




########## ANNOVAR #############################
# add information to table/{sample}_{tumor_normal}.csv
def get_anno_params(_):
    '''
    helper function to create full annovar parameters from input_output[1]
    '''

    # get the full path to humandb
    humandb = os.path.join(config['paths']['static'], config['annovar']['humandb'])
    # get the available anno files
    file_list = list(os.walk(humandb))[0][-1]
    # reduce anno files to the files compatible with genome build version
    build = config['ref']['build']
    build_files = []
    for file in file_list:
        if build in file:
            build_files.append(file)

    # filter the anno protocol for the available files for that genome build        
    anno_refs = config['annovar']['annofiles']
    anno_list = []
    missing_list = []
    for anno in anno_refs:
        for file in build_files:
            if anno in file:
                anno_list.append(anno)
                break
        # if anno has not been found in file during for-loop
        else:
            missing_list.append(anno)

    # create the protocol string
    protocol = ','.join(anno_list)
    print(f"{' '.join(missing_list)} not found for {build}! Doing without.. ")
    # create the operation string 'g,r,f,f,f,f' assuming all but the first three dbs (ref, cytoBand, superDups) in config to be filter-based
    operation_list = []
    for anno in anno_list:
        if "Gene" in anno:
            operation_list.append('g')
        elif anno in ['cytoBand', 'genomicSuperDups']:
            operation_list.append('r')
        else:
            operation_list.append('f')
    operation = ','.join(operation_list)

    options = f'{humandb}/ -buildver {build} -remove -thread {config["annovar"]["threads"]} -protocol {protocol} -operation {operation} -nastring "." -otherinfo'
    return options


def get_filter(filter_dict):
    '''
    get the full path to the filter script with the name filter_name
    '''
    return os.path.join(config['snakedir'], config['paths']['scripts'], 'filters', filter_dict['path'])
