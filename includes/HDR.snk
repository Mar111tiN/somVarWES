rule filter_pileup:
    input:
        filter_file = "table/{sample}_{tumor}-{normal}.filter1.csv",
        bam = get_bam_path
    output: "hdr/{sample}_{tumor}-{normal}_{type}.{chrom}.filter1.pileup"
    threads:
        2
    conda:
        f"../{config['envs']}/align-env.yml"
    params:
        refgen = full_path('genome'),
        qual = f"-q {config['mpileup']['MAPQ']} -Q {config['mpileup']['Q']}",
        mut_bedfile = get_mut_bed
    shell:
        "samtools mpileup -l {params.mut_bedfile} -f {params.refgen} -r {wildcards.chrom} {params.qual} {input.bam} > {output}; "
        "rm -f {params.mut_bedfile} "


rule detect_HDR:
    input:
        bam = get_bam_path,
        filter_file = "table/{sample}_{tumor}-{normal}.filter1.csv",
        pileup = "hdr/{sample}_{tumor}-{normal}_{type}.{chrom}.filter1.pileup"
    output:
        HDR_table = "hdr/{sample}_{tumor}-{normal}_{type}.{chrom}.filter1.HDR.csv"
    conda:
        f"../{config['envs']}/HDR-env.yml"
    threads:
        config['HDR']['threads']
    params:
        genome_split = full_path('genome_split'),
    script:
        "../scripts/runHDR.py"


rule merge_HDR:
    input:
        expand("hdr/{{sample}}_{{tumor}}-{{normal}}_{{normal}}.{chrom}.filter1.HDR.csv", chrom=chrom_list),
        expand("hdr/{{sample}}_{{tumor}}-{{normal}}_{{tumor}}.{chrom}.filter1.HDR.csv", chrom=chrom_list)
    output:
        "table/{sample}_{tumor}-{normal}.filter1.HDR.csv"
    threads:
        1
    run:
        tumor_pattern = f"{wildcards.tumor}-{wildcards.normal}_{wildcards.tumor}"
        normal_pattern = f"{wildcards.tumor}-{wildcards.normal}_{wildcards.normal}"
        # populate an input dict for better looping
        input_list = {'Tumor': [i for i in input if tumor_pattern in i], 'Normal': [i for i in input if normal_pattern in i]}
        base_cols = ['Chr', 'Start', 'End', 'Ref', 'Alt', 'Gene']
        cols = base_cols.copy()
        dfs = {}
        for T_or_N in ['Tumor', 'Normal']:
            HDR_dfs = []
            for HDR_file in input_list[T_or_N]:
                if os.path.isfile(HDR_file):
                    if os.path.getsize(HDR_file ) > 20:
                        HDR_df = pd.read_csv(HDR_file, sep='\t', index_col=False)
                        # cleanup aftHDR
                        # shell(f"rm {EB_file}")
                        if HDR_df.empty:
                            continue
                        HDR_dfs.append(HDR_df)
            # concat
            HDR_df = pd.concat(HDR_dfs).sort_values(['Chr', 'Start'])
            # change columns
            new_cols = {
                'HDRcand': f'{T_or_N}HDRcand',
                'HDRcount': f'{T_or_N}HDRcount',
                'HDRinfo': f'{T_or_N}HDRinfo'
            }

            HDR_df = HDR_df.rename(columns=new_cols)
            # add new_cols to cols
            cols += new_cols.values()
            # load into dfs dict
            dfs[T_or_N] = HDR_df
        
        HDR_merge = pd.merge(dfs['Tumor'], dfs['Normal'], on=base_cols)
        # sort columns
        HDR_merge = sort_df(HDR_merge[cols])

        # ###### PILEUP ANALYSIS ##############################


        HDR_len = len(HDR_merge.query('TumorHDRcount > 0').index)
        HDR_merge.to_csv(output[0], sep='\t', index=False)
        show_output(f"Found {HDR_len} possible HDR mutations. Written HDR file to {output[0]}", color='success')